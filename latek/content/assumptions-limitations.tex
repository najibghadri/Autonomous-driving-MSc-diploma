%----------------------------------------------------------------------------
\chapter{Assumptions made and limitations}
\label{chap:assumptions}
%----------------------------------------------------------------------------

In order to simply the task of scene understanding we need
to define boundaries to measure the success of the detector. 

\section{Ideal traffic situations - only known actors}
The first essential assumption is that there will only be ideal situations which
means that we will only need to detect actors that we expect on the road:
vehicles, bicycles, pedestrians. In the real world foreign objects on the road
are a usual and dangerous phenomenon, however here I won't take that into
account.

\section{Daylight situation}

First of all we are going to specialize to day-light situations only. This
detection with RGB cameras at night is difficult, in order to achieve that we
need other sensors such as Radar, Sonar or LiDAR. As we are only using RGB
cameras we arge going to assume that all driving situations occur in daylight.

\section{Flat plane assumption}
Another important assumption is that the driving field and landscape area is
flat. It isn't difficult to detect object that are a bit higher on the picture
but it is difficult to recognize the curvature of the plane on the image. In
case the detector can interpret curvature and the ego car is on an angled road
the angle data from the gyroscope sensors has to be take into account and
subtracted from the percieved angles. It is generally true that inorder to
recognize true information about the world the relative position and orientation
has to be taken into account.

In order to reduce this complexity,  we are going to only take into account the
objects' position on planar coordinates.

\section{Path, lane and road detection}

As described before there are many ways of detecting lane and the easiest is to
use the Hough transform and detect the lanes directly in front of the car.
However this is not a robust solution: this only gives good results in good
illumination and weather situations. It is true that most situations are like
this but there are still many unpainted roads, dirt roads or simply due to
lightning and weather the lane edges won't be clear.

One robust solution would be to take into account the vehicles in front and
behind us and interpret their path as the right path and regress the lane to
their path. 

Another solution is to take into account previously driven paths. This is the
approach Tesla takes however it is not clear how exactly.

\section{Keypoint detection and orientation}

It is important to determine the orientation of the detected cars on the road,
so that the algorithm knows the depth data corresponds to which side of the
detected vehicle. It is also a clue that helps in determining the direction
of the car.

Detecting keypoints could be done with an algorithm similar to Latent 3D
Keypoints\cite{suwajanakorn_discovery_2018}

\section{Tracking}

The final algorithm does not include tracking, this means that the identity of
each detected actor/object is inconsistent throughout time. Tracking helps
handling occlusion of previously detected pedestrians/vehicles and also in
building up a knowledge base for each actor throughout it's presence in the
scene. This can help in estimating the actor's velocity, acceleration and it
provides a base for interpreting intentions. I simplified the task by not
considering identity throughout time an important factor, eventhough in a real
system it is a must-have.

\section{Only detection and localization}

The final product will be a detector that can detect vehicles and pedestrians up
more than a 100 meters and localize them using stereo vison. The detector work
with a reasonable accuracy error and is built in an extensible way so that
tracking, and improved instance segmentator and lane detection can be plugged
in. The webvisualizer then can be easily extended to show futher information by
a newer version of the detector.
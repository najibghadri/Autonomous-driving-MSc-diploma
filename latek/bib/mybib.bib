% Encoding: UTF-8

@misc{j3016b,
	title = {{J3016B}: {Taxonomy} and {Definitions} for {Terms} {Related} to {Driving} {Automation} {Systems} for {On}-{Road} {Motor} {Vehicles} - {SAE} {International}},
	shorttitle = {{J3016B}},
	url = {https://www.sae.org/standards/content/j3016_201806/},
	abstract = {This SAE Recommended Practice describes motor vehicle driving automation systems that perform part or all of the dynamic driving task (DDT) on a sustained basis. It provides a taxonomy with detailed definitions for six levels of driving automation, ranging from no driving automation (level 0) to ful},
	urldate = {2020-05-28}
}

@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}


@article{suwajanakorn_discovery_2018,
	title = {Discovery of {Latent} {3D} {Keypoints} via {End}-to-end {Geometric} {Reasoning}},
	url = {http://arxiv.org/abs/1807.03146},
	abstract = {This paper presents KeypointNet, an end-to-end geometric reasoning framework to learn an optimal set of category-specific 3D keypoints, along with their detectors. Given a single image, KeypointNet extracts 3D keypoints that are optimized for a downstream task. We demonstrate this framework on 3D pose estimation by proposing a differentiable objective that seeks the optimal set of keypoints for recovering the relative pose between two views of an object. Our model discovers geometrically and semantically consistent keypoints across viewing angles and instances of an object category. Importantly, we find that our end-to-end framework using no ground-truth keypoint annotations outperforms a fully supervised baseline using the same neural network architecture on the task of pose estimation. The discovered 3D keypoints on the car, chair, and plane categories of ShapeNet are visualized at http://keypointnet.github.io/.},
	urldate = {2020-05-30},
	journal = {arXiv:1807.03146 [cs, stat]},
	author = {Suwajanakorn, Supasorn and Snavely, Noah and Tompson, Jonathan and Norouzi, Mohammad},
	month = nov,
	year = {2018},
	note = {arXiv: 1807.03146},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@incollection{NIPS2012_4824,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@Comment{jabref-meta: databaseType:biblatex;}
